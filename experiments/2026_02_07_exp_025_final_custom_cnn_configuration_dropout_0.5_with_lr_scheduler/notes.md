## Experiment: LR Scheduler

All experiments use identical architecture, dataset, seed (42), and training
procedure.

### LR Scheduler
- The same predictions/ curves as experiment 24

Introducing a learning rate scheduler did not alter the training dynamics or final performance, indicating that the selected optimizer and learning rate already provide stable convergence without requiring adaptive learning rate reduction.
