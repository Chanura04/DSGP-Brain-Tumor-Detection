{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5K6rJH/Fiuy8wZGiDGSaD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":325,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0atRyteLEd2","executionInfo":{"status":"ok","timestamp":1769890541467,"user_tz":-330,"elapsed":3452,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"db3a0e55-9309-4fb5-fcb2-257af7fbbccf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import cv2\n","import torch\n","from pathlib import Path\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","from tqdm import tqdm\n","\n","import os\n","\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Data Science Group Project/data/processed/mri\")"]},{"cell_type":"code","source":["image_size = (224, 224)\n","\n","train_transform = A.Compose([\n","    A.Rotate(limit=10, border_mode=cv2.BORDER_REFLECT, p=0.5),\n","\n","    A.HorizontalFlip(p=0.5),\n","\n","    ToTensorV2()\n","], additional_targets={'image0': 'image'})\n","\n","val_test_transform = A.Compose([ToTensorV2()], additional_targets={'image0': 'image'})\n","\n","\n","def zscore_norm_tensor(x):\n","    x = x.float() / 255.0\n","    mean = x.mean(dim=[1, 2], keepdim=True)\n","    std = x.std(dim=[1, 2], keepdim=True, unbiased=False)\n","    return (x - mean) / (std + 1e-8)"],"metadata":{"id":"W0LdzNwYLRwO","executionInfo":{"status":"ok","timestamp":1769890543370,"user_tz":-330,"elapsed":12,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":326,"outputs":[]},{"cell_type":"code","source":["class Transforming:\n","    def __init__(self, raw_dataset_path, processed_dataset_path, image_size, transform, apply_to, classes, save_to):\n","        self.raw_dataset_path = Path(raw_dataset_path)\n","        self.processed_dataset_path = Path(processed_dataset_path)\n","        self.image_size = image_size\n","        self.transform = transform\n","        self.apply_to = apply_to\n","        self.save_to = Path(save_to)\n","        self.class_to_idx = {cls: i for i, cls in enumerate(classes)}\n","        self.source_folders = [f for f in self.raw_dataset_path.rglob(\"*\") if f.is_dir() and (str(f.parent.name) == self.apply_to) and (any(p.is_file() for p in f.iterdir()))]\n","\n","    def transform_images(self):\n","        raw_imgs, proc_imgs, labels = [], [], []\n","\n","        for source in self.source_folders:\n","            for img_file in tqdm(list(source.iterdir()), desc=f\"Processing {source.name}\"):\n","                raw_img = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n","                proc_img = cv2.imread(str(self.processed_dataset_path / source.relative_to(source.parent.parent) / img_file.name), cv2.IMREAD_GRAYSCALE)\n","\n","                raw_img = cv2.resize(raw_img, self.image_size)\n","                proc_img = cv2.resize(proc_img, self.image_size)\n","\n","                # Add channel dim\n","                raw_img = raw_img[..., None]\n","                proc_img = proc_img[..., None]\n","\n","                augmented = self.transform(image=raw_img, image0=proc_img)\n","                raw_tensor = augmented['image']\n","                proc_tensor = augmented['image0']\n","\n","                # Optional: z-score normalization\n","                raw_tensor = zscore_norm_tensor(raw_tensor)\n","                proc_tensor = zscore_norm_tensor(proc_tensor)\n","\n","                raw_imgs.append(raw_tensor)\n","                proc_imgs.append(proc_tensor)\n","                labels.append(self.class_to_idx[source.name])\n","\n","        raw_imgs = torch.stack(raw_imgs)\n","        proc_imgs = torch.stack(proc_imgs)\n","        labels = torch.tensor(labels, dtype=torch.long)\n","\n","        self.save_to.mkdir(parents=True, exist_ok=True)\n","\n","        torch.save((raw_imgs, proc_imgs, labels), f\"{self.save_to}/{self.apply_to}.pt\")"],"metadata":{"id":"5gmh7r_hOIuL","executionInfo":{"status":"ok","timestamp":1769891798115,"user_tz":-330,"elapsed":16,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":348,"outputs":[]},{"cell_type":"code","source":["classes = ['glioma', 'meningioma', 'pituitary']"],"metadata":{"id":"9bD7wzgvrxWO","executionInfo":{"status":"ok","timestamp":1769891798936,"user_tz":-330,"elapsed":7,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":349,"outputs":[]},{"cell_type":"code","source":["transforming_train = Transforming(\"raw\", \"processed_nlmd_224\", image_size, train_transform, \"train\", classes, \"transform_v1\")\n","transforming_train.transform_images()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4k3RUI9PNqVR","executionInfo":{"status":"ok","timestamp":1769891908096,"user_tz":-330,"elapsed":108523,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"d48c20d6-28e0-426b-fe4b-c4f5f5580d01"},"execution_count":350,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing glioma: 100%|██████████| 1278/1278 [00:35<00:00, 35.55it/s]\n","Processing meningioma: 100%|██████████| 1197/1197 [00:27<00:00, 42.91it/s]\n","Processing pituitary: 100%|██████████| 706/706 [00:16<00:00, 43.17it/s]\n"]}]},{"cell_type":"code","source":["transforming_val = Transforming(\"raw\", \"processed_nlmd_224\", image_size, val_test_transform, \"val\", classes, \"transform_v1\")\n","transforming_val.transform_images()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wrp6-a4vOYll","executionInfo":{"status":"ok","timestamp":1769891971990,"user_tz":-330,"elapsed":20877,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"5e7d9874-a2b6-4970-870d-a027ff9af231"},"execution_count":351,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing glioma: 100%|██████████| 365/365 [00:07<00:00, 51.39it/s]\n","Processing meningioma: 100%|██████████| 342/342 [00:06<00:00, 51.28it/s]\n","Processing pituitary: 100%|██████████| 201/201 [00:03<00:00, 52.47it/s]\n"]}]},{"cell_type":"code","source":["transforming_test = Transforming(\"raw\", \"processed_nlmd_224\", image_size, val_test_transform, \"test\", classes, \"transform_v1\")\n","transforming_test.transform_images()"],"metadata":{"id":"LkN9ruW-h0yQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769891984483,"user_tz":-330,"elapsed":12490,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"2a7c21e5-b143-4661-91e9-a13394273592"},"execution_count":352,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing glioma: 100%|██████████| 183/183 [00:03<00:00, 53.08it/s]\n","Processing meningioma: 100%|██████████| 171/171 [00:04<00:00, 34.50it/s]\n","Processing pituitary: 100%|██████████| 102/102 [00:01<00:00, 51.98it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T3RJJy7wxEqs"},"execution_count":null,"outputs":[]}]}