{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMSeeqTQsZRwHQQhS0+aLdR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b78697a4fb4e484698724f6dc1630ba3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2263b801038940eca582849529a5dfb7","IPY_MODEL_0114379b1116462fabf6d736debcd3f4","IPY_MODEL_1cfc673174f44ad48abd67da3d048cb2"],"layout":"IPY_MODEL_813735e8f442426e9626f9946e437bee"}},"2263b801038940eca582849529a5dfb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_115153429c914b499a37fd0717560874","placeholder":"​","style":"IPY_MODEL_d2288ac326d949918c8092e809e7c82f","value":"100%"}},"0114379b1116462fabf6d736debcd3f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1ba47f111848c6a42a6e763c74acb4","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99169922a7e7449eb318cce0c7b2a2bb","value":15}},"1cfc673174f44ad48abd67da3d048cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eadf78b9c4fd41b48dae73c2c4bad1fb","placeholder":"​","style":"IPY_MODEL_aac13eb3ac534b7f90ff1e50361828a6","value":" 15/15 [05:35&lt;00:00, 22.53s/it]"}},"813735e8f442426e9626f9946e437bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115153429c914b499a37fd0717560874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2288ac326d949918c8092e809e7c82f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1ba47f111848c6a42a6e763c74acb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99169922a7e7449eb318cce0c7b2a2bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eadf78b9c4fd41b48dae73c2c4bad1fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac13eb3ac534b7f90ff1e50361828a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78LMvV9WCkzf","executionInfo":{"status":"ok","timestamp":1769967891964,"user_tz":-330,"elapsed":27353,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"55ce2d61-661a-46b2-9ece-e10723700c26"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Experiment: 2026_02_01_exp_012_vgg16_baseline\n","Goal:\n","Dataset:\n","Notes:\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YXYvXqkiCXnw","executionInfo":{"status":"ok","timestamp":1769967891980,"user_tz":-330,"elapsed":6,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"afc31e61-7d47-4733-fc2e-6c2f26a99d26"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nExperiment: 2026_02_01_exp_012_vgg16_baseline\\nGoal:\\nDataset:\\nNotes:\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Data Science Group Project\")\n","\n","print(os.getcwd())\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsy9F0Y7Cgw_","executionInfo":{"status":"ok","timestamp":1769967893255,"user_tz":-330,"elapsed":1271,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"36762977-fbbd-489b-9fa0-170ce49c375b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Data Science Group Project\n","['data', 'experiments', 'JustTests', 'OLD', 'MoveImagesFinal.ipynb', 'Splitting Dataset Into Train_Validation_Test_Sets.ipynb', 'RemovingBlackFinal.ipynb', 'Top-View Image Selection From MRI and CT Dataset.ipynb']\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6eu6SOCyCOgI","executionInfo":{"status":"ok","timestamp":1769968211080,"user_tz":-330,"elapsed":10518,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"outputs":[],"source":["# =====================================================\n","# Imports\n","# =====================================================\n","\n","import platform\n","from pathlib import Path\n","import os\n","import cv2\n","import torch\n","import torch.multiprocessing as mp\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","import yaml\n","import json\n","import pandas as pd\n","import random\n","from torchvision import models\n","\n","# =====================================================\n","# Config & Reproducibility\n","# =====================================================\n","\n","def load_config(path):\n","    with open(path, \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","\n","# =====================================================\n","# Dataset\n","# =====================================================\n","\n","class DualImageDataset(Dataset):\n","    def __init__(self, path):\n","        # Load once\n","        self.raw_imgs, self.proc_imgs, self.labels = torch.load(path)\n","\n","        # Ensure proper dtype\n","        self.raw_imgs = self.raw_imgs.float()\n","        self.proc_imgs = self.proc_imgs.float()\n","        self.labels = self.labels.long()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.raw_imgs[idx], self.proc_imgs[idx], self.labels[idx]\n","\n","def dataset(transformed_data_dir, cfg):\n","    train_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"train_path\"])\n","    val_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"val_path\"])\n","    test_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"test_path\"])\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","\n","# =====================================================\n","# Dataloaders\n","# =====================================================\n","\n","def dataloader(cfg, train_dataset, val_dataset, test_dataset):\n","    train_dataloader = DataLoader(train_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","\n","    print(f\"Number of training samples: {len(train_dataset)}\")\n","    print(f\"Number of validation samples: {len(val_dataset)}\")\n","    print(f\"Number of testing samples: {len(test_dataset)}\")\n","\n","    print(f\"Length of TrainDataloader: {len(train_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of ValDataloader: {len(val_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of TestDataloader: {len(test_dataloader)} batches of {cfg['training']['batch_size']}\")\n","\n","    return train_dataloader, val_dataloader, test_dataloader\n","\n","\n","# =====================================================\n","# Model\n","# =====================================================\n","\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        self.model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n","\n","        self.model.features[0] = nn.Conv2d(2, 64, kernel_size=3, padding=1, bias=True)\n","\n","        for param in self.model.features.parameters():\n","            param.requires_grad = False\n","\n","        self.model.classifier[-1] = nn.Linear(self.model.classifier[-1].in_features, num_classes)\n","\n","    def forward(self, raw_img, processed_img):\n","        x = torch.cat([raw_img, processed_img], dim=1)  # Concatenate raw + processed channels -> [B, 2, H, W]\n","        return self.model(x)\n","\n","\n","def make_model(cfg, classes, device):\n","    model = VGG16(num_classes=len(classes)).to(device)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"training\"][\"lr\"])\n","\n","    return model, loss_func, optimizer\n","\n","\n","# =====================================================\n","# Training / Evaluation Utils\n","# =====================================================\n","\n","# =====================================================\n","# Train\n","# =====================================================\n","\n","def train_step(model, train_dataloader, loss_func, optimizer, device):\n","    train_loss, train_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.train()\n","\n","    for batch, (raw_X, processed_X, y) in enumerate(train_dataloader):\n","        raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","        train_y_pred = model(raw_X, processed_X)\n","\n","        loss = loss_func(train_y_pred, y)\n","        train_loss += loss.item()\n","\n","        # accuracy\n","        correct += (train_y_pred.argmax(dim=1) == y).sum().item()\n","        total += y.size(0)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    train_loss /= len(train_dataloader)\n","    train_acc = 100.0 * correct / total\n","\n","    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n\")\n","    return train_loss, train_acc\n","\n","\n","# =====================================================\n","# Validation\n","# =====================================================\n","\n","def val_step(model, val_dataloader, loss_func, device):\n","    val_loss, val_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in val_dataloader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            val_y_pred = model(raw_X, processed_X)\n","\n","            val_loss += loss_func(val_y_pred, y).item()\n","\n","            # accuracy\n","            correct += (val_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        val_loss /= len(val_dataloader)\n","        val_acc = 100.0 * correct / total\n","\n","    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.2f}%\\n\")\n","    return val_loss, val_acc\n","\n","\n","def train_and_evaluate(model, epochs, train_dataloader, val_dataloader, loss_func, optimizer,\n","                       device):\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_func, optimizer, device)\n","        val_loss, val_acc = val_step(model, val_dataloader, loss_func, device)\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","    return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n","\n","\n","# =====================================================\n","# Test\n","# =====================================================\n","\n","def test_step(model, test_data_loader, loss_func, device):\n","    test_loss, test_acc = 0, 0\n","    correct = 0\n","    total = 0\n","    y_test_list = []\n","    y_pred_list = []\n","    y_pred_prob_list = []\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in test_data_loader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            test_y_pred = model(raw_X, processed_X)\n","            y_pred_prob_list.append(torch.softmax(test_y_pred, dim=1))\n","\n","            test_loss += loss_func(test_y_pred, y).item()\n","\n","            y_test_list.append(y.cpu())\n","            y_pred_list.append(test_y_pred.argmax(dim=1).cpu())\n","\n","            correct += (test_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        test_loss /= len(test_data_loader)\n","        test_acc = 100.0 * correct / total\n","\n","    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n","    return y_test_list, y_pred_list, y_pred_prob_list, test_acc"]},{"cell_type":"code","source":["experiment_path = Path(\"experiments/2026_02_01_exp_012_vgg16_baseline\")\n","\n","config = load_config(experiment_path / \"config.yaml\")\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","# torch.use_deterministic_algorithms(True)\n","\n","random.seed(config[\"seed\"])\n","np.random.seed(config[\"seed\"])\n","torch.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed_all(config[\"seed\"])\n","\n","device = \"cuda\" if config[\"device\"] == \"cuda\" and torch.cuda.is_available() else \"cpu\"\n","\n","train_dataset, val_dataset, test_dataset = dataset(Path(\"data/processed/mri\"), config)\n","\n","train_dataloader, val_dataloader, test_dataloader = dataloader(config, train_dataset, val_dataset, test_dataset)\n","\n","classes = ['glioma', 'meningioma', 'pituitary']\n","\n","model, loss_func, optimizer = make_model(config, classes, device)\n","\n","train_loss_list, train_acc_list, val_loss_list, val_acc_list = train_and_evaluate(model,\n","                                                                                    config[\"training\"][\"epochs\"],\n","                                                                                    train_dataloader, val_dataloader,\n","                                                                                    loss_func, optimizer, device)\n","\n","checkpoint = {\n","    \"epoch\": config[\"training\"][\"epochs\"],\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict(),\n","    \"config\": config,\n","    \"best_val_loss\": np.min(val_loss_list),\n","}\n","\n","torch.save(checkpoint, experiment_path / \"checkpoint.pth\")\n","\n","y_test_list, y_pred_list, y_pred_prob_list, test_accuracy = test_step(model, test_dataloader, loss_func, device)\n","\n","y_test_list = torch.cat(y_test_list).numpy()  # true labels\n","y_pred_list = torch.cat(y_pred_list).numpy()  # predicted class\n","y_pred_prob_list = torch.cat(y_pred_prob_list).cpu().numpy()  # predicted probabilities\n","\n","print(f\"Test: {y_test_list}\")\n","print(f\"Predicted: {y_pred_list}\")\n","print(f\"Predicted Probability: {y_pred_prob_list}\")\n","\n","# Convert metrics to JSON-friendly format\n","metrics = {\n","    \"train_loss\": [float(l) for l in train_loss_list],\n","    \"train_accuracy\": [float(a) for a in train_acc_list],\n","    \"val_loss\": [float(l) for l in val_loss_list],\n","    \"val_accuracy\": [float(a) for a in val_acc_list],\n","    \"test_accuracy\": test_accuracy,\n","    \"classes\": classes,\n","    \"epochs\": config[\"training\"][\"epochs\"],\n","    \"num_train_samples\": len(train_dataset),\n","    \"num_val_samples\": len(val_dataset),\n","    \"num_test_samples\": len(test_dataset),\n","    \"best_val_epoch\": int(np.argmin(val_loss_list)) + 1,\n","    \"best_val_loss\": float(np.min(val_loss_list)),\n","    \"best_val_accuracy\": float(val_acc_list[np.argmin(val_loss_list)])\n","}\n","\n","# Save metrics\n","metrics_path = experiment_path / \"metrics.json\"\n","with open(metrics_path, \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\"Metrics saved to {metrics_path}\")\n","\n","# Create DataFrame\n","metrics_df = pd.DataFrame({\n","    \"epoch\": list(range(config[\"training\"][\"epochs\"])),\n","    \"train_loss\": train_loss_list,\n","    \"train_accuracy\": [a for a in train_acc_list],\n","    \"val_loss\": val_loss_list,\n","    \"val_accuracy\": [a for a in val_acc_list]\n","})\n","\n","# Save to CSV\n","metrics_df.to_csv(experiment_path / \"train_val_metrics.csv\", index=False)\n","print(\"Train/Val metrics saved to train_val_metrics.csv\")\n","\n","# Convert predicted probabilities to a DataFrame\n","prob_df = pd.DataFrame(y_pred_prob_list, columns=[f\"prob_{cls}\" for cls in classes])\n","\n","# Create main DataFrame\n","test_df = pd.DataFrame({\"y_true\": y_test_list, \"y_pred\": y_pred_list})\n","\n","# Concatenate probabilities\n","test_df = pd.concat([test_df, prob_df], axis=1)\n","\n","# Save to CSV\n","test_df.to_csv(experiment_path / \"test_predictions.csv\", index=False)\n","print(\"Test predictions saved to test_predictions.csv\")\n","\n","env_info = {\n","    \"python_version\": platform.python_version(),\n","    \"pytorch_version\": torch.__version__,\n","    \"cuda_version\": torch.version.cuda,\n","    \"cudnn_version\": torch.backends.cudnn.version(),\n","    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    \"os\": platform.platform(),\n","}\n","\n","env_path = experiment_path / \"env_info.json\"\n","with open(env_path, \"w\") as f:\n","    json.dump(env_info, f, indent=4)\n","\n","print(f\"Environment Info saved to {env_path}\")"],"metadata":{"id":"1ZnX8JmMGB5y","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b78697a4fb4e484698724f6dc1630ba3","2263b801038940eca582849529a5dfb7","0114379b1116462fabf6d736debcd3f4","1cfc673174f44ad48abd67da3d048cb2","813735e8f442426e9626f9946e437bee","115153429c914b499a37fd0717560874","d2288ac326d949918c8092e809e7c82f","ad1ba47f111848c6a42a6e763c74acb4","99169922a7e7449eb318cce0c7b2a2bb","eadf78b9c4fd41b48dae73c2c4bad1fb","aac13eb3ac534b7f90ff1e50361828a6"]},"outputId":"f372057e-aeff-4fad-f7f7-46e4d122305c","executionInfo":{"status":"ok","timestamp":1769968615177,"user_tz":-330,"elapsed":394962,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples: 3181\n","Number of validation samples: 908\n","Number of testing samples: 456\n","Length of TrainDataloader: 100 batches of 32\n","Length of ValDataloader: 29 batches of 32\n","Length of TestDataloader: 15 batches of 32\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 528M/528M [00:07<00:00, 75.6MB/s]\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b78697a4fb4e484698724f6dc1630ba3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train loss: 0.62897 | Train acc: 70.32%\n","\n","Val loss: 0.31473 | Val acc: 87.78%\n","\n","Train loss: 0.35820 | Train acc: 85.41%\n","\n","Val loss: 0.35458 | Val acc: 88.44%\n","\n","Train loss: 0.27044 | Train acc: 89.28%\n","\n","Val loss: 0.30412 | Val acc: 89.43%\n","\n","Train loss: 0.24511 | Train acc: 90.69%\n","\n","Val loss: 0.20876 | Val acc: 92.62%\n","\n","Train loss: 0.17151 | Train acc: 93.49%\n","\n","Val loss: 0.25397 | Val acc: 92.07%\n","\n","Train loss: 0.18770 | Train acc: 93.37%\n","\n","Val loss: 0.23530 | Val acc: 93.83%\n","\n","Train loss: 0.12438 | Train acc: 95.10%\n","\n","Val loss: 0.20065 | Val acc: 95.81%\n","\n","Train loss: 0.15666 | Train acc: 94.37%\n","\n","Val loss: 0.41248 | Val acc: 88.33%\n","\n","Train loss: 0.11753 | Train acc: 95.44%\n","\n","Val loss: 0.25976 | Val acc: 94.38%\n","\n","Train loss: 0.13598 | Train acc: 95.35%\n","\n","Val loss: 0.23561 | Val acc: 95.04%\n","\n","Train loss: 0.10475 | Train acc: 96.51%\n","\n","Val loss: 0.21551 | Val acc: 95.04%\n","\n","Train loss: 0.09133 | Train acc: 96.32%\n","\n","Val loss: 0.17604 | Val acc: 96.48%\n","\n","Train loss: 0.10259 | Train acc: 96.48%\n","\n","Val loss: 0.34444 | Val acc: 90.42%\n","\n","Train loss: 0.11867 | Train acc: 95.50%\n","\n","Val loss: 0.19240 | Val acc: 95.70%\n","\n","Train loss: 0.08118 | Train acc: 96.98%\n","\n","Val loss: 0.19593 | Val acc: 96.26%\n","\n","Test loss: 0.06302 | Test acc: 98.03%\n","\n","Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n"," 1 0 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted Probability: [[5.9245819e-01 4.0641496e-01 1.1268642e-03]\n"," [9.3800008e-01 6.0891345e-02 1.1086105e-03]\n"," [9.6386141e-01 3.5269253e-02 8.6929544e-04]\n"," ...\n"," [2.8573695e-06 3.4422320e-07 9.9999678e-01]\n"," [5.3206242e-19 6.7116847e-16 1.0000000e+00]\n"," [2.8846621e-12 8.7209386e-09 1.0000000e+00]]\n","Metrics saved to experiments/2026_02_01_exp_012_vgg16_baseline/metrics.json\n","Train/Val metrics saved to train_val_metrics.csv\n","Test predictions saved to test_predictions.csv\n","Environment Info saved to experiments/2026_02_01_exp_012_vgg16_baseline/env_info.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"C2FhPMjqfIVt"},"execution_count":null,"outputs":[]}]}