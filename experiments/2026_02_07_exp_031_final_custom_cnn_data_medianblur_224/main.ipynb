{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO7cMn7cD6ayRuomR4OsbmH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78LMvV9WCkzf","executionInfo":{"status":"ok","timestamp":1770462109705,"user_tz":-330,"elapsed":37628,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"f7d64dca-2d14-4c10-fd2c-a6036e8b2e5b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Experiment: 2026_02_07_exp_031_final_custom_cnn_data_medianblur_224\n","Goal:\n","Dataset:\n","Notes:\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YXYvXqkiCXnw","executionInfo":{"status":"ok","timestamp":1770462109708,"user_tz":-330,"elapsed":26,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"17997c50-1d44-4386-cf66-878abd879c2a"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nExperiment: 2026_02_07_exp_031_final_custom_cnn_data_medianblur_224\\nGoal:\\nDataset:\\nNotes:\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Data Science Group Project\")\n","\n","print(os.getcwd())\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsy9F0Y7Cgw_","executionInfo":{"status":"ok","timestamp":1770462111340,"user_tz":-330,"elapsed":1643,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"49ef51a3-0926-4a3f-8680-401c2f2a4930"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Data Science Group Project\n","['data', 'experiments', 'JustTests', 'OLD', 'MoveImagesFinal.ipynb', 'Splitting Dataset Into Train_Validation_Test_Sets.ipynb', 'RemovingBlackFinal.ipynb', 'Top-View Image Selection From MRI and CT Dataset.ipynb', 'old experiments']\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6eu6SOCyCOgI","executionInfo":{"status":"ok","timestamp":1770462117379,"user_tz":-330,"elapsed":6038,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"outputs":[],"source":["# =====================================================\n","# Imports\n","# =====================================================\n","\n","import platform\n","from pathlib import Path\n","import os\n","import cv2\n","import torch\n","import torch.multiprocessing as mp\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","import yaml\n","import json\n","import pandas as pd\n","import random\n","\n","# =====================================================\n","# Config & Reproducibility\n","# =====================================================\n","\n","def load_config(path):\n","    with open(path, \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","\n","# =====================================================\n","# Dataset\n","# =====================================================\n","\n","class DualImageDataset(Dataset):\n","    def __init__(self, path):\n","        # Load once\n","        self.raw_imgs, self.proc_imgs, self.labels = torch.load(path)\n","\n","        # Ensure proper dtype\n","        self.raw_imgs = self.raw_imgs.float()\n","        self.proc_imgs = self.proc_imgs.float()\n","        self.labels = self.labels.long()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.raw_imgs[idx], self.proc_imgs[idx], self.labels[idx]\n","\n","def dataset(transformed_data_dir, cfg):\n","    train_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"train_path\"])\n","    val_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"val_path\"])\n","    test_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"test_path\"])\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","\n","# =====================================================\n","# Dataloaders\n","# =====================================================\n","\n","def dataloader(cfg, train_dataset, val_dataset, test_dataset):\n","    train_dataloader = DataLoader(train_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","\n","    print(f\"Number of training samples: {len(train_dataset)}\")\n","    print(f\"Number of validation samples: {len(val_dataset)}\")\n","    print(f\"Number of testing samples: {len(test_dataset)}\")\n","\n","    print(f\"Length of TrainDataloader: {len(train_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of ValDataloader: {len(val_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of TestDataloader: {len(test_dataloader)} batches of {cfg['training']['batch_size']}\")\n","\n","    return train_dataloader, val_dataloader, test_dataloader\n","\n","\n","# =====================================================\n","# Model\n","# =====================================================\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self, input_shape, hidden_units, output_shape, dropout, cfg):\n","        super().__init__()\n","\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        # Compute flatten size dynamically\n","        with torch.no_grad():\n","            x = torch.zeros(1, input_shape, *tuple(cfg[\"data\"][\"image_size\"]))  # batch_size=1, input_shape channels\n","            x = self.conv_block_1(x)\n","            x = self.conv_block_2(x)\n","            n_features = x.numel() // x.shape[0]  # total features per sample\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Dropout(p=dropout),\n","            nn.Linear(in_features=n_features, out_features=output_shape)\n","        )\n","\n","    def forward(self, raw_img, processed_img):\n","        x = torch.cat([raw_img, processed_img], dim=1)  # Concatenate raw + processed channels -> [B, 2, H, W]\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","def make_model(cfg, classes, device):\n","    model = CustomCNN(input_shape=cfg[\"model\"][\"input_dim\"], hidden_units=cfg[\"model\"][\"hidden_units\"],\n","                      output_shape=len(classes), dropout=cfg[\"model\"][\"dropout\"], cfg=cfg).to(device)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.RMSprop(model.parameters(), lr=cfg[\"training\"][\"lr\"])\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode=\"min\", factor=cfg[\"training\"][\"factor\"], patience=cfg[\"training\"][\"patience\"])\n","\n","    return model, loss_func, optimizer, scheduler\n","\n","\n","# =====================================================\n","# Training / Evaluation Utils\n","# =====================================================\n","\n","# =====================================================\n","# Train\n","# =====================================================\n","\n","def train_step(model, train_dataloader, loss_func, optimizer, device):\n","    train_loss, train_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.train()\n","\n","    for batch, (raw_X, processed_X, y) in enumerate(train_dataloader):\n","        raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","        train_y_pred = model(raw_X, processed_X)\n","\n","        loss = loss_func(train_y_pred, y)\n","        train_loss += loss.item()\n","\n","        # accuracy\n","        correct += (train_y_pred.argmax(dim=1) == y).sum().item()\n","        total += y.size(0)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    train_loss /= len(train_dataloader)\n","    train_acc = 100.0 * correct / total\n","\n","    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n\")\n","    return train_loss, train_acc\n","\n","\n","# =====================================================\n","# Validation\n","# =====================================================\n","\n","def val_step(model, val_dataloader, loss_func, device):\n","    val_loss, val_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in val_dataloader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            val_y_pred = model(raw_X, processed_X)\n","\n","            val_loss += loss_func(val_y_pred, y).item()\n","\n","            # accuracy\n","            correct += (val_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        val_loss /= len(val_dataloader)\n","        val_acc = 100.0 * correct / total\n","\n","    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.2f}%\\n\")\n","    return val_loss, val_acc\n","\n","\n","def train_and_evaluate(model, epochs, train_dataloader, val_dataloader, loss_func, optimizer, scheduler, device):\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_func, optimizer, device)\n","        val_loss, val_acc = val_step(model, val_dataloader, loss_func, device)\n","\n","        scheduler.step(val_loss)\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","        current_lr = optimizer.param_groups[0][\"lr\"]\n","        print(f\"Epoch {epoch+1} | LR: {current_lr:.6e}\")\n","\n","    return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n","\n","\n","# =====================================================\n","# Test\n","# =====================================================\n","\n","def test_step(model, test_data_loader, loss_func, device):\n","    test_loss, test_acc = 0, 0\n","    correct = 0\n","    total = 0\n","    y_test_list = []\n","    y_pred_list = []\n","    y_pred_prob_list = []\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in test_data_loader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            test_y_pred = model(raw_X, processed_X)\n","            y_pred_prob_list.append(torch.softmax(test_y_pred, dim=1))\n","\n","            test_loss += loss_func(test_y_pred, y).item()\n","\n","            y_test_list.append(y.cpu())\n","            y_pred_list.append(test_y_pred.argmax(dim=1).cpu())\n","\n","            correct += (test_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        test_loss /= len(test_data_loader)\n","        test_acc = 100.0 * correct / total\n","\n","    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n","    return y_test_list, y_pred_list, y_pred_prob_list, test_acc"]},{"cell_type":"code","source":["experiment_path = Path(\"experiments/2026_02_07_exp_031_final_custom_cnn_data_medianblur_224\")\n","\n","config = load_config(experiment_path / \"config.yaml\")\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","# torch.use_deterministic_algorithms(True)\n","\n","random.seed(config[\"seed\"])\n","np.random.seed(config[\"seed\"])\n","torch.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed_all(config[\"seed\"])\n","\n","device = \"cuda\" if config[\"device\"] == \"cuda\" and torch.cuda.is_available() else \"cpu\"\n","\n","train_dataset, val_dataset, test_dataset = dataset(Path(\"data/processed/mri\"), config)\n","\n","train_dataloader, val_dataloader, test_dataloader = dataloader(config, train_dataset, val_dataset, test_dataset)\n","\n","classes = ['glioma', 'meningioma', 'pituitary']\n","\n","model, loss_func, optimizer, scheduler = make_model(config, classes, device)\n","\n","train_loss_list, train_acc_list, val_loss_list, val_acc_list = train_and_evaluate(model,\n","                                                                                    config[\"training\"][\"epochs\"],\n","                                                                                    train_dataloader, val_dataloader,\n","                                                                                    loss_func, optimizer, scheduler, device)\n","\n","checkpoint = {\n","    \"epoch\": config[\"training\"][\"epochs\"],\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict(),\n","    \"config\": config,\n","    \"best_val_loss\": np.min(val_loss_list),\n","}\n","\n","torch.save(checkpoint, experiment_path / \"checkpoint.pth\")\n","\n","y_test_list, y_pred_list, y_pred_prob_list, test_accuracy = test_step(model, test_dataloader, loss_func, device)\n","\n","y_test_list = torch.cat(y_test_list).numpy()  # true labels\n","y_pred_list = torch.cat(y_pred_list).numpy()  # predicted class\n","y_pred_prob_list = torch.cat(y_pred_prob_list).cpu().numpy()  # predicted probabilities\n","\n","print(f\"Test: {y_test_list}\")\n","print(f\"Predicted: {y_pred_list}\")\n","print(f\"Predicted Probability: {y_pred_prob_list}\")\n","\n","# Convert metrics to JSON-friendly format\n","metrics = {\n","    \"train_loss\": [float(l) for l in train_loss_list],\n","    \"train_accuracy\": [float(a) for a in train_acc_list],\n","    \"val_loss\": [float(l) for l in val_loss_list],\n","    \"val_accuracy\": [float(a) for a in val_acc_list],\n","    \"test_accuracy\": test_accuracy,\n","    \"classes\": classes,\n","    \"epochs\": config[\"training\"][\"epochs\"],\n","    \"num_train_samples\": len(train_dataset),\n","    \"num_val_samples\": len(val_dataset),\n","    \"num_test_samples\": len(test_dataset),\n","    \"best_val_epoch\": int(np.argmin(val_loss_list)) + 1,\n","    \"best_val_loss\": float(np.min(val_loss_list)),\n","    \"best_val_accuracy\": float(val_acc_list[np.argmin(val_loss_list)])\n","}\n","\n","# Save metrics\n","metrics_path = experiment_path / \"metrics.json\"\n","with open(metrics_path, \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\"Metrics saved to {metrics_path}\")\n","\n","# Create DataFrame\n","metrics_df = pd.DataFrame({\n","    \"epoch\": list(range(config[\"training\"][\"epochs\"])),\n","    \"train_loss\": train_loss_list,\n","    \"train_accuracy\": [a for a in train_acc_list],\n","    \"val_loss\": val_loss_list,\n","    \"val_accuracy\": [a for a in val_acc_list]\n","})\n","\n","# Save to CSV\n","metrics_df.to_csv(experiment_path / \"train_val_metrics.csv\", index=False)\n","print(\"Train/Val metrics saved to train_val_metrics.csv\")\n","\n","# Convert predicted probabilities to a DataFrame\n","prob_df = pd.DataFrame(y_pred_prob_list, columns=[f\"prob_{cls}\" for cls in classes])\n","\n","# Create main DataFrame\n","test_df = pd.DataFrame({\"y_true\": y_test_list, \"y_pred\": y_pred_list})\n","\n","# Concatenate probabilities\n","test_df = pd.concat([test_df, prob_df], axis=1)\n","\n","# Save to CSV\n","test_df.to_csv(experiment_path / \"test_predictions.csv\", index=False)\n","print(\"Test predictions saved to test_predictions.csv\")\n","\n","env_info = {\n","    \"python_version\": platform.python_version(),\n","    \"pytorch_version\": torch.__version__,\n","    \"cuda_version\": torch.version.cuda,\n","    \"cudnn_version\": torch.backends.cudnn.version(),\n","    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    \"os\": platform.platform(),\n","}\n","\n","env_path = experiment_path / \"env_info.json\"\n","with open(env_path, \"w\") as f:\n","    json.dump(env_info, f, indent=4)\n","\n","print(f\"Environment Info saved to {env_path}\")"],"metadata":{"id":"1ZnX8JmMGB5y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71c49fcd-80b4-4175-e04f-84352e88fb5f","executionInfo":{"status":"ok","timestamp":1770462350991,"user_tz":-330,"elapsed":233607,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples: 3181\n","Number of validation samples: 908\n","Number of testing samples: 456\n","Length of TrainDataloader: 100 batches of 32\n","Length of ValDataloader: 29 batches of 32\n","Length of TestDataloader: 15 batches of 32\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.65957 | Train acc: 69.60%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 1/50 [00:04<03:54,  4.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.51507 | Val acc: 75.11%\n","\n","Epoch 1 | LR: 3.000000e-04\n","Train loss: 0.43157 | Train acc: 81.39%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:08<03:14,  4.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.58789 | Val acc: 71.59%\n","\n","Epoch 2 | LR: 3.000000e-04\n","Train loss: 0.33656 | Train acc: 85.95%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:11<02:59,  3.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.29123 | Val acc: 88.99%\n","\n","Epoch 3 | LR: 3.000000e-04\n","Train loss: 0.27719 | Train acc: 88.75%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:15<02:51,  3.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.26390 | Val acc: 89.65%\n","\n","Epoch 4 | LR: 3.000000e-04\n","Train loss: 0.23176 | Train acc: 90.79%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:19<02:45,  3.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.22285 | Val acc: 91.52%\n","\n","Epoch 5 | LR: 3.000000e-04\n","Train loss: 0.19801 | Train acc: 92.71%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:22<02:40,  3.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.20075 | Val acc: 93.39%\n","\n","Epoch 6 | LR: 3.000000e-04\n","Train loss: 0.17746 | Train acc: 92.90%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:26<02:36,  3.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.17628 | Val acc: 94.93%\n","\n","Epoch 7 | LR: 3.000000e-04\n","Train loss: 0.16012 | Train acc: 94.12%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:29<02:32,  3.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.22202 | Val acc: 89.65%\n","\n","Epoch 8 | LR: 3.000000e-04\n","Train loss: 0.13124 | Train acc: 95.32%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:33<02:29,  3.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.16050 | Val acc: 94.93%\n","\n","Epoch 9 | LR: 3.000000e-04\n","Train loss: 0.12152 | Train acc: 95.47%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:37<02:25,  3.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.13582 | Val acc: 96.26%\n","\n","Epoch 10 | LR: 3.000000e-04\n","Train loss: 0.09817 | Train acc: 96.38%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:40<02:22,  3.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.13592 | Val acc: 95.81%\n","\n","Epoch 11 | LR: 3.000000e-04\n","Train loss: 0.09064 | Train acc: 96.76%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:44<02:19,  3.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.19255 | Val acc: 93.28%\n","\n","Epoch 12 | LR: 3.000000e-04\n","Train loss: 0.08134 | Train acc: 96.70%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:48<02:18,  3.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.13725 | Val acc: 95.48%\n","\n","Epoch 13 | LR: 3.000000e-04\n","Train loss: 0.07543 | Train acc: 97.52%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:52<02:14,  3.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11038 | Val acc: 96.70%\n","\n","Epoch 14 | LR: 3.000000e-04\n","Train loss: 0.05667 | Train acc: 98.30%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:55<02:11,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.44876 | Val acc: 82.27%\n","\n","Epoch 15 | LR: 3.000000e-04\n","Train loss: 0.05469 | Train acc: 98.08%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:59<02:07,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10544 | Val acc: 97.36%\n","\n","Epoch 16 | LR: 3.000000e-04\n","Train loss: 0.04432 | Train acc: 98.93%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [01:03<02:03,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.13795 | Val acc: 96.48%\n","\n","Epoch 17 | LR: 3.000000e-04\n","Train loss: 0.03746 | Train acc: 98.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:07<02:00,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.09518 | Val acc: 97.36%\n","\n","Epoch 18 | LR: 3.000000e-04\n","Train loss: 0.03786 | Train acc: 98.65%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:11<01:56,  3.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11041 | Val acc: 97.25%\n","\n","Epoch 19 | LR: 3.000000e-04\n","Train loss: 0.02787 | Train acc: 99.03%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:14<01:53,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.09548 | Val acc: 97.36%\n","\n","Epoch 20 | LR: 3.000000e-04\n","Train loss: 0.02888 | Train acc: 99.06%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:18<01:49,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11978 | Val acc: 97.47%\n","\n","Epoch 21 | LR: 3.000000e-04\n","Train loss: 0.03023 | Train acc: 98.96%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:22<01:46,  3.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10761 | Val acc: 97.03%\n","\n","Epoch 22 | LR: 1.500000e-04\n","Train loss: 0.02039 | Train acc: 99.37%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:26<01:42,  3.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10493 | Val acc: 97.36%\n","\n","Epoch 23 | LR: 1.500000e-04\n","Train loss: 0.01427 | Train acc: 99.56%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:30<01:38,  3.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10570 | Val acc: 97.14%\n","\n","Epoch 24 | LR: 1.500000e-04\n","Train loss: 0.01401 | Train acc: 99.53%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:33<01:34,  3.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10146 | Val acc: 97.47%\n","\n","Epoch 25 | LR: 1.500000e-04\n","Train loss: 0.01243 | Train acc: 99.50%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:37<01:30,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11489 | Val acc: 97.03%\n","\n","Epoch 26 | LR: 7.500000e-05\n","Train loss: 0.01067 | Train acc: 99.81%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:41<01:26,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10858 | Val acc: 97.25%\n","\n","Epoch 27 | LR: 7.500000e-05\n","Train loss: 0.00835 | Train acc: 99.81%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:45<01:22,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10349 | Val acc: 97.14%\n","\n","Epoch 28 | LR: 7.500000e-05\n","Train loss: 0.01150 | Train acc: 99.62%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:48<01:18,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10391 | Val acc: 97.36%\n","\n","Epoch 29 | LR: 7.500000e-05\n","Train loss: 0.00914 | Train acc: 99.75%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:52<01:15,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10051 | Val acc: 97.58%\n","\n","Epoch 30 | LR: 3.750000e-05\n","Train loss: 0.00873 | Train acc: 99.81%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:56<01:11,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.12027 | Val acc: 97.69%\n","\n","Epoch 31 | LR: 3.750000e-05\n","Train loss: 0.01081 | Train acc: 99.65%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [02:00<01:07,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10466 | Val acc: 97.58%\n","\n","Epoch 32 | LR: 3.750000e-05\n","Train loss: 0.00727 | Train acc: 99.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [02:03<01:03,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10432 | Val acc: 97.69%\n","\n","Epoch 33 | LR: 3.750000e-05\n","Train loss: 0.00515 | Train acc: 99.94%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [02:07<01:00,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11325 | Val acc: 97.36%\n","\n","Epoch 34 | LR: 1.875000e-05\n","Train loss: 0.00808 | Train acc: 99.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [02:11<00:56,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10773 | Val acc: 97.69%\n","\n","Epoch 35 | LR: 1.875000e-05\n","Train loss: 0.00474 | Train acc: 99.94%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [02:15<00:52,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10853 | Val acc: 97.47%\n","\n","Epoch 36 | LR: 1.875000e-05\n","Train loss: 0.00585 | Train acc: 99.91%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [02:18<00:48,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11061 | Val acc: 97.47%\n","\n","Epoch 37 | LR: 1.875000e-05\n","Train loss: 0.00687 | Train acc: 99.87%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [02:22<00:44,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11149 | Val acc: 97.58%\n","\n","Epoch 38 | LR: 9.375000e-06\n","Train loss: 0.00459 | Train acc: 99.94%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:26<00:41,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11022 | Val acc: 97.47%\n","\n","Epoch 39 | LR: 9.375000e-06\n","Train loss: 0.00496 | Train acc: 99.91%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:30<00:37,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10890 | Val acc: 97.58%\n","\n","Epoch 40 | LR: 9.375000e-06\n","Train loss: 0.00502 | Train acc: 99.87%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:33<00:33,  3.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10786 | Val acc: 97.69%\n","\n","Epoch 41 | LR: 9.375000e-06\n","Train loss: 0.00654 | Train acc: 99.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:37<00:29,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11229 | Val acc: 97.36%\n","\n","Epoch 42 | LR: 4.687500e-06\n","Train loss: 0.00518 | Train acc: 99.91%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:41<00:26,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10932 | Val acc: 97.58%\n","\n","Epoch 43 | LR: 4.687500e-06\n","Train loss: 0.00528 | Train acc: 99.87%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [02:45<00:22,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11031 | Val acc: 97.58%\n","\n","Epoch 44 | LR: 4.687500e-06\n","Train loss: 0.00583 | Train acc: 99.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [02:48<00:18,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.10985 | Val acc: 97.58%\n","\n","Epoch 45 | LR: 4.687500e-06\n","Train loss: 0.00755 | Train acc: 99.78%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [02:52<00:15,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11245 | Val acc: 97.47%\n","\n","Epoch 46 | LR: 2.343750e-06\n","Train loss: 0.00428 | Train acc: 99.94%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [02:56<00:11,  3.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11144 | Val acc: 97.47%\n","\n","Epoch 47 | LR: 2.343750e-06\n","Train loss: 0.00667 | Train acc: 99.78%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [03:00<00:07,  3.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11010 | Val acc: 97.58%\n","\n","Epoch 48 | LR: 2.343750e-06\n","Train loss: 0.00507 | Train acc: 99.94%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [03:03<00:03,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11108 | Val acc: 97.47%\n","\n","Epoch 49 | LR: 2.343750e-06\n","Train loss: 0.00653 | Train acc: 99.84%\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [03:07<00:00,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Val loss: 0.11054 | Val acc: 97.58%\n","\n","Epoch 50 | LR: 1.171875e-06\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test loss: 0.07680 | Test acc: 97.37%\n","\n","Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted Probability: [[9.9569327e-01 4.3067718e-03 2.1899416e-11]\n"," [9.9981314e-01 1.8686397e-04 3.6006981e-08]\n"," [9.8227251e-01 1.7727520e-02 1.3956402e-12]\n"," ...\n"," [1.1625159e-12 1.7333116e-07 9.9999988e-01]\n"," [1.7111974e-30 5.7146137e-15 1.0000000e+00]\n"," [7.8100459e-25 1.9099600e-07 9.9999976e-01]]\n","Metrics saved to experiments/2026_02_07_exp_031_final_custom_cnn_data_medianblur_224/metrics.json\n","Train/Val metrics saved to train_val_metrics.csv\n","Test predictions saved to test_predictions.csv\n","Environment Info saved to experiments/2026_02_07_exp_031_final_custom_cnn_data_medianblur_224/env_info.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"C2FhPMjqfIVt","executionInfo":{"status":"ok","timestamp":1770462351003,"user_tz":-330,"elapsed":3,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":6,"outputs":[]}]}