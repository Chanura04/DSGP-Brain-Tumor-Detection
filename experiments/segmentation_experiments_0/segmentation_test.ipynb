{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e758c57175b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!pip install scikit-learn\n",
    "!pip install \"tensorflow==2.10\"\n",
    "!pip install \"numpy<2\" --force-reinstall\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f880244175d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization,Conv2DTranspose,Concatenate,Input,Activation,Flatten,Dense\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from  tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "# from scipy.io import loadmat\n",
    "# import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce5240f4aa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc77564089cdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58affe18d13be22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"C:\\IIT campus\\Second Year\\DSGP\\Segementation_1\\Segementation_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4831e5b2c3b44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files=sorted(os.listdir('C:\\IIT campus\\Second Year\\DSGP\\Segementation_1\\images'))\n",
    "mask_files=sorted(os.listdir('C:\\IIT campus\\Second Year\\DSGP\\Segementation_1\\masks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980377dab72ecc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_files[:10])\n",
    "print(mask_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83417de1ec03194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_mask(image_path,mask_path):\n",
    "    count=0\n",
    "    for image_file,mask_file in zip(image_files,mask_files):\n",
    "        if count>=6:\n",
    "            break\n",
    "        image_path_full=os.path.join(image_path,image_file)\n",
    "        mask_path_full=os.path.join(mask_path,mask_file)\n",
    "\n",
    "        image=cv2.imread(image_path_full)\n",
    "        mask=cv2.imread(mask_path_full,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "                raise ValueError(f\"Image at path {imagepath_full} could not be loaded\")\n",
    "        if mask is None:\n",
    "                raise ValueError(f\"Mask at path {maskpath_full} could not be loaded\")\n",
    "\n",
    "        mask_3ch=cv2.merge([mask,mask,mask])\n",
    "        image_rgb=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10,10))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Image')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask)\n",
    "        plt.title('Mask')\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        overlay = cv2.addWeighted(image_rgb, 0.7, mask_3ch, 0.3, 0)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(\"Image with overlay\")\n",
    "\n",
    "        plt.show()\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd90a9941b3e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='C:\\IIT campus\\Second Year\\DSGP\\Segementation_1\\images'\n",
    "mask_path='C:\\IIT campus\\Second Year\\DSGP\\Segementation_1\\masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12451efe7df9602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_mask(image_path,mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7c775f4cd7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size=[]\n",
    "masks_size=[]\n",
    "#Check images shape\n",
    "for image_file, mask_file in tqdm(zip(image_files, mask_files)):\n",
    "\n",
    "    imagepath_full = os.path.join(image_path, image_file)\n",
    "    maskpath_full = os.path.join(mask_path, mask_file)\n",
    "\n",
    "    image = cv2.imread(imagepath_full)\n",
    "    mask = cv2.imread(maskpath_full)\n",
    "\n",
    "    images_size.append(image.shape)\n",
    "    masks_size.append(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653120d1d8d7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(set(images_size)))\n",
    "print(list(set(masks_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a174d70530bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE=224\n",
    "CHANNEL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ed6ba9f0dfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_images_masks(num_samples=None):\n",
    "    images=[]\n",
    "    masks=[]\n",
    "\n",
    "    if num_samples is not None:\n",
    "        selected_image_files = image_files[:num_samples]\n",
    "        selected_mask_files = mask_files[:num_samples]\n",
    "    else:\n",
    "        selected_image_files = image_files\n",
    "        selected_mask_files = mask_files\n",
    "\n",
    "    for image_file, mask_file in tqdm(zip(selected_image_files, selected_mask_files)):\n",
    "        imagepathfull=os.path.join(image_path,image_file)\n",
    "        maskpathfull=os.path.join(mask_path,mask_file)\n",
    "\n",
    "        image = cv2.imread(imagepathfull,cv2.IMREAD_GRAYSCALE)  #load img\n",
    "        image = cv2.resize(image,(SIZE,SIZE))\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        image = image/255.0  #normalizes pixel values 0-1\n",
    "        images.append(image)\n",
    "\n",
    "        mask = cv2.imread(maskpathfull,cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask,(SIZE,SIZE))\n",
    "        mask = mask/255.0\n",
    "        masks.append(mask)\n",
    "    #add a channel to mask (depth of information per pixel(1))\n",
    "    return np.array(images), np.expand_dims(np.array(masks), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551dce3f45c5c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdafe6fbb892d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=preprocessing_images_masks(num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f150dc69d0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of X:',X.shape)\n",
    "print('Shape of y:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45216ee16c89e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a69380a2c9f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of X_train',X_train.shape)\n",
    "print('The shape of y_train',y_train.shape)\n",
    "print('The shape of X_test',X_test.shape)\n",
    "print('The shape of y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9951a820a1c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid division by zero\n",
    "smooth = 1e-15\n",
    "\n",
    "#decor- save custom function with model\n",
    "@keras.saving.register_keras_serializable()\n",
    "#metric for overlap between prediction and ground truth\n",
    "def dice_coef(y_true, y_pred):\n",
    "    #convert multi dimensions to 1D\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    #common positive pixels\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "\n",
    "    #balances TN and FP\n",
    "    return (2. * intersection + smooth) / (\n",
    "        tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth\n",
    "    )\n",
    "\n",
    "# @register_keras_serializable()\n",
    "@keras.saving.register_keras_serializable()\n",
    "#define loss function base one coef\n",
    "def dice_loss(y_true, y_pred):\n",
    "    #Reduce tumor mismatch\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c536505bf02b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log tensorflow informations\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee247201bd341c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "train_datagen=(ImageDataGenerator\n",
    "               (brightness_range=(0.9,1.1),#Randomly adjust brightness\n",
    "               zoom_range=[.9,1.1],#Random zoom applied\n",
    "               fill_mode='nearest') #Prevents unnatural\n",
    "               )\n",
    "val_datagen=ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436be492b84011e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts features and learn pattern from the input image\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input) #learn patterns\n",
    "    x = BatchNormalization()(x)  #stabilizes training\n",
    "    x = Activation(\"relu\")(x)    #network to learn complex features.(Introduces non-linearity)\n",
    "\n",
    "    #combine learn pattern into meaningful region\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d8c8b33758972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase resolution and merge encoder info in tumor mask\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    #Upsampling (double spatial resolution)\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c02bcbbb87cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def build_resnet50_unet(input_shape):\n",
    "#     \"\"\" Input \"\"\"\n",
    "#     inputs = Input(shape=input_shape)\n",
    "#\n",
    "#     \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
    "#     resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "#\n",
    "#     \"\"\" Encoder \"\"\"\n",
    "#     s1 = inputs                                         ## (224 x 224) - Use inputs directly\n",
    "#     s2 = resnet50.get_layer(\"conv1_relu\").output        ## (112 x 112)\n",
    "#     s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (56 x 56)\n",
    "#     s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (28 x 28)\n",
    "#\n",
    "#     \"\"\" Bridge \"\"\"\n",
    "#     b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (14 x 14)\n",
    "#\n",
    "#     \"\"\" Decoder \"\"\"\n",
    "#     d1 = decoder_block(b1, s4, 512)                     ## (28 x 28)\n",
    "#     d2 = decoder_block(d1, s3, 256)                     ## (56 x 56)\n",
    "#     d3 = decoder_block(d2, s2, 128)                     ## (112 x 112)\n",
    "#     d4 = decoder_block(d3, s1, 64)                      ## (224 x 224)\n",
    "#\n",
    "#     \"\"\" Output \"\"\"\n",
    "#     outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "#\n",
    "#     model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n",
    "#     return model\n",
    "#\n",
    "# input_shape = (224, 224, 3)\n",
    "# model = build_resnet50_unet(input_shape)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9e55aed2585c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_light_resnet50_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    # Encoder (skip connections)\n",
    "    s1 = inputs                                      # 224 x 224 x 3\n",
    "    s2 = resnet50.get_layer(\"conv1_relu\").output     # 112 x 112 x 64\n",
    "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  # 56 x 56 x 256\n",
    "\n",
    "    # Bridge(compressed view)\n",
    "    b1 = resnet50.get_layer(\"conv3_block4_out\").output  # 28 x 28 x 512\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s3, 128)   # 56 x 56\n",
    "    d2 = decoder_block(d1, s2, 64)    # 112 x 112\n",
    "    d3 = decoder_block(d2, s1, 32)    # 224 x 224\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"LightResNet50_U-Net\")\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "model = build_light_resnet50_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3080db48b89f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint  = ModelCheckpoint('best_model_checkpoint.keras', save_best_only=True,\n",
    "                                    monitor='val_loss', mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "reduceLR = ReduceLROnPlateau(patience=4, verbose=2, monitor='val_loss',min_lr=1e-4, mode='min')\n",
    "\n",
    "callback_list = [early_stopping, reduceLR, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13747877c16dee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator = train_datagen.flow( X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow(X_test, y_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20151ee67cf87fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=dice_loss,\n",
    "              metrics=[dice_coef, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab03105afd6113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=4,  # Reduced from 32 to 4\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e331b2fc8e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet50_trained_model_batch_size_4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a4876a7b1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245ad491c8b54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565b27b7009646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,dice_coef,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss is {loss}')\n",
    "print(f'Accuracy is {accuracy}')\n",
    "print(f'Dice_Coef is {dice_coef}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833266b90220746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet_resnet50_backbone.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe689fe1b7de7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\n",
    "    \"best_model_checkpoint_1\",   # â† folder, NOT file\n",
    "    compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be415f910aba8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43590fd79a691b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(X_test[i],cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"True Mask\")\n",
    "    plt.imshow(y_test[i].squeeze(), cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(y_pred[i].squeeze(), cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3abe1655eaa0863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43b633a61c9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#\n",
    "# def overlay_mask(image, mask, alpha=0.4):\n",
    "#     overlay = image.copy()\n",
    "#     red = np.zeros_like(image)\n",
    "#     red[..., 0] = 255\n",
    "#\n",
    "#     overlay[mask > 0] = (\n",
    "#         (1 - alpha) * image[mask > 0] +\n",
    "#         alpha * red[mask > 0]\n",
    "#     ).astype(np.uint8)\n",
    "#\n",
    "#     return overlay\n",
    "#\n",
    "\n",
    "def overlay_mask(image, mask, alpha=0.4):\n",
    "    # 1. Ensure the image is RGB even if it's grayscale\n",
    "    if len(image.shape) == 2 or image.shape[-1] == 1:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_rgb = image.copy()\n",
    "\n",
    "    # 2. Create a red overlay\n",
    "    overlay = image_rgb.copy()\n",
    "    red_color = np.zeros_like(image_rgb)\n",
    "    red_color[:, :] = [255, 0, 0]  # Set all mask pixels to Red\n",
    "\n",
    "    # 3. Blend only where the mask exists\n",
    "    mask_indices = mask > 0\n",
    "    overlay[mask_indices] = (\n",
    "        (1 - alpha) * image_rgb[mask_indices] +\n",
    "        alpha * red_color[mask_indices]\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    return overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf7fe2fcd09b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_show = 6\n",
    "fig, axs = plt.subplots(n_show, 3, figsize=(12, 4 * n_show))\n",
    "\n",
    "for i in range(n_show):\n",
    "\n",
    "    # Image (already loaded)\n",
    "    img = X_test[i]\n",
    "\n",
    "    # If normalized, bring back to uint8 for display\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Ground truth mask\n",
    "    gt_mask = y_test[i]\n",
    "    if gt_mask.ndim == 3:\n",
    "        gt_mask = gt_mask.squeeze()\n",
    "    gt_mask = (gt_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Prepare input for model\n",
    "    input_img = img.astype(np.float32) / 255.0\n",
    "    input_img = np.expand_dims(input_img, axis=0)\n",
    "\n",
    "    # Predict mask\n",
    "    pred_prob = model.predict(input_img, verbose=0)[0, :, :, 0]\n",
    "    pred_mask = (pred_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Overlay prediction\n",
    "    overlay_img = overlay_mask(img, pred_mask)\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    axs[i, 0].imshow(img, cmap=\"gray\")\n",
    "    axs[i, 0].set_title(\"Original Image\")\n",
    "    axs[i, 0].axis(\"off\")\n",
    "\n",
    "    axs[i, 1].imshow(gt_mask, cmap=\"gray\")\n",
    "    axs[i, 1].set_title(\"Ground Truth Mask\")\n",
    "    axs[i, 1].axis(\"off\")\n",
    "\n",
    "    axs[i, 2].imshow(overlay_img)\n",
    "\n",
    "    axs[i, 2].set_title(\"Predicted Overlay\")\n",
    "    axs[i, 2].axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
