{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPx9i3bMDwqZoia6hawdPSm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8db31e05dc7746b8bbfb2966521844d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b431ec0b767d42d0ae210a6fca391577","IPY_MODEL_9728f37bba8f4affadd65d711aee1954","IPY_MODEL_33ff582da25e4352b22179f872e1ae73"],"layout":"IPY_MODEL_951887870588441b847c5a90d9ab7d9e"}},"b431ec0b767d42d0ae210a6fca391577":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a546a97bc267444182515b333e33d2e7","placeholder":"​","style":"IPY_MODEL_8e4d4d440a254cebb5155f5ea81bf402","value":"100%"}},"9728f37bba8f4affadd65d711aee1954":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b3457e811c144d79c9ab3b15bf390fa","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_816797a7ec144886a0f484553ca17d15","value":15}},"33ff582da25e4352b22179f872e1ae73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c63330316dc8472c917cf4df9c035c48","placeholder":"​","style":"IPY_MODEL_2bbdb7da001f4db0975e755db45c2312","value":" 15/15 [00:57&lt;00:00,  3.83s/it]"}},"951887870588441b847c5a90d9ab7d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a546a97bc267444182515b333e33d2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e4d4d440a254cebb5155f5ea81bf402":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b3457e811c144d79c9ab3b15bf390fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816797a7ec144886a0f484553ca17d15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c63330316dc8472c917cf4df9c035c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bbdb7da001f4db0975e755db45c2312":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78LMvV9WCkzf","executionInfo":{"status":"ok","timestamp":1770050560747,"user_tz":-330,"elapsed":51825,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"51c795bc-bee7-47a8-a386-7ce58cbc8620"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Experiment: 2026_02_02_exp_019_custom_cnn_optim_RMSprop_lr_3e-4\n","Goal:\n","Dataset:\n","Notes:\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YXYvXqkiCXnw","executionInfo":{"status":"ok","timestamp":1770050560767,"user_tz":-330,"elapsed":14,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"54beda9b-f04c-4825-b9f3-d8e3fb09bf80"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nExperiment: 2026_02_02_exp_019_custom_cnn_optim_RMSprop_lr_3e-4\\nGoal:\\nDataset:\\nNotes:\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Data Science Group Project\")\n","\n","print(os.getcwd())\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsy9F0Y7Cgw_","executionInfo":{"status":"ok","timestamp":1770050562381,"user_tz":-330,"elapsed":1610,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"2f896848-7194-464d-8072-2d12c109b694"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Data Science Group Project\n","['data', 'experiments', 'JustTests', 'OLD', 'MoveImagesFinal.ipynb', 'Splitting Dataset Into Train_Validation_Test_Sets.ipynb', 'RemovingBlackFinal.ipynb', 'Top-View Image Selection From MRI and CT Dataset.ipynb', 'old experiments']\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6eu6SOCyCOgI","executionInfo":{"status":"ok","timestamp":1770050568626,"user_tz":-330,"elapsed":6237,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"outputs":[],"source":["# =====================================================\n","# Imports\n","# =====================================================\n","\n","import platform\n","from pathlib import Path\n","import os\n","import cv2\n","import torch\n","import torch.multiprocessing as mp\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","import yaml\n","import json\n","import pandas as pd\n","import random\n","\n","# =====================================================\n","# Config & Reproducibility\n","# =====================================================\n","\n","def load_config(path):\n","    with open(path, \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","\n","# =====================================================\n","# Dataset\n","# =====================================================\n","\n","class DualImageDataset(Dataset):\n","    def __init__(self, path):\n","        # Load once\n","        self.raw_imgs, self.proc_imgs, self.labels = torch.load(path)\n","\n","        # Ensure proper dtype\n","        self.raw_imgs = self.raw_imgs.float()\n","        self.proc_imgs = self.proc_imgs.float()\n","        self.labels = self.labels.long()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.raw_imgs[idx], self.proc_imgs[idx], self.labels[idx]\n","\n","def dataset(transformed_data_dir, cfg):\n","    train_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"train_path\"])\n","    val_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"val_path\"])\n","    test_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"test_path\"])\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","\n","# =====================================================\n","# Dataloaders\n","# =====================================================\n","\n","def dataloader(cfg, train_dataset, val_dataset, test_dataset):\n","    train_dataloader = DataLoader(train_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","\n","    print(f\"Number of training samples: {len(train_dataset)}\")\n","    print(f\"Number of validation samples: {len(val_dataset)}\")\n","    print(f\"Number of testing samples: {len(test_dataset)}\")\n","\n","    print(f\"Length of TrainDataloader: {len(train_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of ValDataloader: {len(val_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of TestDataloader: {len(test_dataloader)} batches of {cfg['training']['batch_size']}\")\n","\n","    return train_dataloader, val_dataloader, test_dataloader\n","\n","\n","# =====================================================\n","# Model\n","# =====================================================\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self, input_shape, hidden_units, output_shape, cfg):\n","        super().__init__()\n","\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        # Compute flatten size dynamically\n","        with torch.no_grad():\n","            x = torch.zeros(1, input_shape, *tuple(cfg[\"data\"][\"image_size\"]))  # batch_size=1, input_shape channels\n","            x = self.conv_block_1(x)\n","            x = self.conv_block_2(x)\n","            n_features = x.numel() // x.shape[0]  # total features per sample\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=n_features, out_features=output_shape)\n","        )\n","\n","    def forward(self, raw_img, processed_img):\n","        x = torch.cat([raw_img, processed_img], dim=1)  # Concatenate raw + processed channels -> [B, 2, H, W]\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","def make_model(cfg, classes, device):\n","    model = CustomCNN(input_shape=cfg[\"model\"][\"input_dim\"], hidden_units=cfg[\"model\"][\"hidden_units\"],\n","                      output_shape=len(classes), cfg=cfg).to(device)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.RMSprop(model.parameters(), lr=cfg[\"training\"][\"lr\"])\n","\n","    return model, loss_func, optimizer\n","\n","\n","# =====================================================\n","# Training / Evaluation Utils\n","# =====================================================\n","\n","# =====================================================\n","# Train\n","# =====================================================\n","\n","def train_step(model, train_dataloader, loss_func, optimizer, device):\n","    train_loss, train_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.train()\n","\n","    for batch, (raw_X, processed_X, y) in enumerate(train_dataloader):\n","        raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","        train_y_pred = model(raw_X, processed_X)\n","\n","        loss = loss_func(train_y_pred, y)\n","        train_loss += loss.item()\n","\n","        # accuracy\n","        correct += (train_y_pred.argmax(dim=1) == y).sum().item()\n","        total += y.size(0)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    train_loss /= len(train_dataloader)\n","    train_acc = 100.0 * correct / total\n","\n","    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n\")\n","    return train_loss, train_acc\n","\n","\n","# =====================================================\n","# Validation\n","# =====================================================\n","\n","def val_step(model, val_dataloader, loss_func, device):\n","    val_loss, val_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in val_dataloader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            val_y_pred = model(raw_X, processed_X)\n","\n","            val_loss += loss_func(val_y_pred, y).item()\n","\n","            # accuracy\n","            correct += (val_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        val_loss /= len(val_dataloader)\n","        val_acc = 100.0 * correct / total\n","\n","    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.2f}%\\n\")\n","    return val_loss, val_acc\n","\n","\n","def train_and_evaluate(model, epochs, train_dataloader, val_dataloader, loss_func, optimizer,\n","                       device):\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_func, optimizer, device)\n","        val_loss, val_acc = val_step(model, val_dataloader, loss_func, device)\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","    return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n","\n","\n","# =====================================================\n","# Test\n","# =====================================================\n","\n","def test_step(model, test_data_loader, loss_func, device):\n","    test_loss, test_acc = 0, 0\n","    correct = 0\n","    total = 0\n","    y_test_list = []\n","    y_pred_list = []\n","    y_pred_prob_list = []\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in test_data_loader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            test_y_pred = model(raw_X, processed_X)\n","            y_pred_prob_list.append(torch.softmax(test_y_pred, dim=1))\n","\n","            test_loss += loss_func(test_y_pred, y).item()\n","\n","            y_test_list.append(y.cpu())\n","            y_pred_list.append(test_y_pred.argmax(dim=1).cpu())\n","\n","            correct += (test_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        test_loss /= len(test_data_loader)\n","        test_acc = 100.0 * correct / total\n","\n","    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n","    return y_test_list, y_pred_list, y_pred_prob_list, test_acc"]},{"cell_type":"code","source":["experiment_path = Path(\"experiments/2026_02_02_exp_019_custom_cnn_optim_RMSprop_lr_3e-4\")\n","\n","config = load_config(experiment_path / \"config.yaml\")\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","# torch.use_deterministic_algorithms(True)\n","\n","random.seed(config[\"seed\"])\n","np.random.seed(config[\"seed\"])\n","torch.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed_all(config[\"seed\"])\n","\n","device = \"cuda\" if config[\"device\"] == \"cuda\" and torch.cuda.is_available() else \"cpu\"\n","\n","train_dataset, val_dataset, test_dataset = dataset(Path(\"data/processed/mri\"), config)\n","\n","train_dataloader, val_dataloader, test_dataloader = dataloader(config, train_dataset, val_dataset, test_dataset)\n","\n","classes = ['glioma', 'meningioma', 'pituitary']\n","\n","model, loss_func, optimizer = make_model(config, classes, device)\n","\n","train_loss_list, train_acc_list, val_loss_list, val_acc_list = train_and_evaluate(model,\n","                                                                                    config[\"training\"][\"epochs\"],\n","                                                                                    train_dataloader, val_dataloader,\n","                                                                                    loss_func, optimizer, device)\n","\n","checkpoint = {\n","    \"epoch\": config[\"training\"][\"epochs\"],\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict(),\n","    \"config\": config,\n","    \"best_val_loss\": np.min(val_loss_list),\n","}\n","\n","torch.save(checkpoint, experiment_path / \"checkpoint.pth\")\n","\n","y_test_list, y_pred_list, y_pred_prob_list, test_accuracy = test_step(model, test_dataloader, loss_func, device)\n","\n","y_test_list = torch.cat(y_test_list).numpy()  # true labels\n","y_pred_list = torch.cat(y_pred_list).numpy()  # predicted class\n","y_pred_prob_list = torch.cat(y_pred_prob_list).cpu().numpy()  # predicted probabilities\n","\n","print(f\"Test: {y_test_list}\")\n","print(f\"Predicted: {y_pred_list}\")\n","print(f\"Predicted Probability: {y_pred_prob_list}\")\n","\n","# Convert metrics to JSON-friendly format\n","metrics = {\n","    \"train_loss\": [float(l) for l in train_loss_list],\n","    \"train_accuracy\": [float(a) for a in train_acc_list],\n","    \"val_loss\": [float(l) for l in val_loss_list],\n","    \"val_accuracy\": [float(a) for a in val_acc_list],\n","    \"test_accuracy\": test_accuracy,\n","    \"classes\": classes,\n","    \"epochs\": config[\"training\"][\"epochs\"],\n","    \"num_train_samples\": len(train_dataset),\n","    \"num_val_samples\": len(val_dataset),\n","    \"num_test_samples\": len(test_dataset),\n","    \"best_val_epoch\": int(np.argmin(val_loss_list)) + 1,\n","    \"best_val_loss\": float(np.min(val_loss_list)),\n","    \"best_val_accuracy\": float(val_acc_list[np.argmin(val_loss_list)])\n","}\n","\n","# Save metrics\n","metrics_path = experiment_path / \"metrics.json\"\n","with open(metrics_path, \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\"Metrics saved to {metrics_path}\")\n","\n","# Create DataFrame\n","metrics_df = pd.DataFrame({\n","    \"epoch\": list(range(config[\"training\"][\"epochs\"])),\n","    \"train_loss\": train_loss_list,\n","    \"train_accuracy\": [a for a in train_acc_list],\n","    \"val_loss\": val_loss_list,\n","    \"val_accuracy\": [a for a in val_acc_list]\n","})\n","\n","# Save to CSV\n","metrics_df.to_csv(experiment_path / \"train_val_metrics.csv\", index=False)\n","print(\"Train/Val metrics saved to train_val_metrics.csv\")\n","\n","# Convert predicted probabilities to a DataFrame\n","prob_df = pd.DataFrame(y_pred_prob_list, columns=[f\"prob_{cls}\" for cls in classes])\n","\n","# Create main DataFrame\n","test_df = pd.DataFrame({\"y_true\": y_test_list, \"y_pred\": y_pred_list})\n","\n","# Concatenate probabilities\n","test_df = pd.concat([test_df, prob_df], axis=1)\n","\n","# Save to CSV\n","test_df.to_csv(experiment_path / \"test_predictions.csv\", index=False)\n","print(\"Test predictions saved to test_predictions.csv\")\n","\n","env_info = {\n","    \"python_version\": platform.python_version(),\n","    \"pytorch_version\": torch.__version__,\n","    \"cuda_version\": torch.version.cuda,\n","    \"cudnn_version\": torch.backends.cudnn.version(),\n","    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    \"os\": platform.platform(),\n","}\n","\n","env_path = experiment_path / \"env_info.json\"\n","with open(env_path, \"w\") as f:\n","    json.dump(env_info, f, indent=4)\n","\n","print(f\"Environment Info saved to {env_path}\")"],"metadata":{"id":"1ZnX8JmMGB5y","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8db31e05dc7746b8bbfb2966521844d0","b431ec0b767d42d0ae210a6fca391577","9728f37bba8f4affadd65d711aee1954","33ff582da25e4352b22179f872e1ae73","951887870588441b847c5a90d9ab7d9e","a546a97bc267444182515b333e33d2e7","8e4d4d440a254cebb5155f5ea81bf402","7b3457e811c144d79c9ab3b15bf390fa","816797a7ec144886a0f484553ca17d15","c63330316dc8472c917cf4df9c035c48","2bbdb7da001f4db0975e755db45c2312"]},"outputId":"58f5cd36-a4fb-401f-cfd7-4b70d9275192","executionInfo":{"status":"ok","timestamp":1770050652520,"user_tz":-330,"elapsed":83884,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples: 3181\n","Number of validation samples: 908\n","Number of testing samples: 456\n","Length of TrainDataloader: 100 batches of 32\n","Length of ValDataloader: 29 batches of 32\n","Length of TestDataloader: 15 batches of 32\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db31e05dc7746b8bbfb2966521844d0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train loss: 0.65430 | Train acc: 69.92%\n","\n","Val loss: 0.54328 | Val acc: 73.68%\n","\n","Train loss: 0.41505 | Train acc: 82.14%\n","\n","Val loss: 0.54782 | Val acc: 73.02%\n","\n","Train loss: 0.32362 | Train acc: 87.17%\n","\n","Val loss: 0.29335 | Val acc: 89.32%\n","\n","Train loss: 0.27242 | Train acc: 89.28%\n","\n","Val loss: 0.27268 | Val acc: 90.20%\n","\n","Train loss: 0.22943 | Train acc: 91.42%\n","\n","Val loss: 0.25835 | Val acc: 92.29%\n","\n","Train loss: 0.18200 | Train acc: 93.30%\n","\n","Val loss: 0.23560 | Val acc: 93.28%\n","\n","Train loss: 0.15634 | Train acc: 94.37%\n","\n","Val loss: 0.19441 | Val acc: 95.48%\n","\n","Train loss: 0.12808 | Train acc: 95.79%\n","\n","Val loss: 0.19814 | Val acc: 94.49%\n","\n","Train loss: 0.09855 | Train acc: 96.98%\n","\n","Val loss: 0.17155 | Val acc: 96.04%\n","\n","Train loss: 0.08764 | Train acc: 96.98%\n","\n","Val loss: 0.18189 | Val acc: 95.70%\n","\n","Train loss: 0.05757 | Train acc: 98.30%\n","\n","Val loss: 0.18507 | Val acc: 95.48%\n","\n","Train loss: 0.07313 | Train acc: 97.58%\n","\n","Val loss: 0.17999 | Val acc: 97.25%\n","\n","Train loss: 0.04694 | Train acc: 98.62%\n","\n","Val loss: 0.16367 | Val acc: 97.14%\n","\n","Train loss: 0.04313 | Train acc: 98.55%\n","\n","Val loss: 0.17949 | Val acc: 96.59%\n","\n","Train loss: 0.02371 | Train acc: 99.43%\n","\n","Val loss: 0.19088 | Val acc: 96.59%\n","\n","Test loss: 0.11377 | Test acc: 96.71%\n","\n","Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n"," 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted Probability: [[8.0123341e-01 1.9876643e-01 1.0211915e-07]\n"," [9.2147529e-01 7.7529222e-02 9.9541387e-04]\n"," [5.3874880e-01 4.6125114e-01 1.3408404e-11]\n"," ...\n"," [1.3723686e-10 3.9192633e-07 9.9999964e-01]\n"," [2.2505222e-20 1.9535873e-13 1.0000000e+00]\n"," [4.1004896e-22 1.7320211e-09 1.0000000e+00]]\n","Metrics saved to experiments/2026_02_02_exp_019_custom_cnn_optim_RMSprop_lr_3e-4/metrics.json\n","Train/Val metrics saved to train_val_metrics.csv\n","Test predictions saved to test_predictions.csv\n","Environment Info saved to experiments/2026_02_02_exp_019_custom_cnn_optim_RMSprop_lr_3e-4/env_info.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"C2FhPMjqfIVt"},"execution_count":null,"outputs":[]}]}