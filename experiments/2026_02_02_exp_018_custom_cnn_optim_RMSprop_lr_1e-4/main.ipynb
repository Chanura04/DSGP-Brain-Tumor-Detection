{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNPYgZiuFyA1PuXQxnftlb3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2e344e44b6634b76acb614899f219271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9f23e45b7674e5b9222c562db97b565","IPY_MODEL_e61f1994140f41e2b8dfb3f44d8cefa4","IPY_MODEL_e30120392fd3472c8a816ccbabd3448f"],"layout":"IPY_MODEL_63825fbcee5f40049661e3ddcc15bf7e"}},"c9f23e45b7674e5b9222c562db97b565":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fdba78512f34ca7831db2de108e1204","placeholder":"​","style":"IPY_MODEL_77f9880874fd439abb42664698b8c7e5","value":"100%"}},"e61f1994140f41e2b8dfb3f44d8cefa4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ec4eab9e31147c597ad013042c35237","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_befd29eb338c4d46931d27f3790d45c5","value":15}},"e30120392fd3472c8a816ccbabd3448f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22d80e5ebbc44e18afa9a8fa4eb3c812","placeholder":"​","style":"IPY_MODEL_edb64121660d4b47aa3ecfcc88e5953c","value":" 15/15 [00:56&lt;00:00,  3.65s/it]"}},"63825fbcee5f40049661e3ddcc15bf7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fdba78512f34ca7831db2de108e1204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77f9880874fd439abb42664698b8c7e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ec4eab9e31147c597ad013042c35237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"befd29eb338c4d46931d27f3790d45c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22d80e5ebbc44e18afa9a8fa4eb3c812":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edb64121660d4b47aa3ecfcc88e5953c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78LMvV9WCkzf","executionInfo":{"status":"ok","timestamp":1770049887405,"user_tz":-330,"elapsed":27325,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"ff8d705c-7df4-42b3-cd9d-7125acc28453"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Experiment: 2026_02_02_exp_018_custom_cnn_optim_RMSprop_lr_1e-4\n","Goal:\n","Dataset:\n","Notes:\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YXYvXqkiCXnw","executionInfo":{"status":"ok","timestamp":1770049887458,"user_tz":-330,"elapsed":58,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"1f755ed7-7e88-44d3-fabb-b269aeb65b29"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nExperiment: 2026_02_02_exp_018_custom_cnn_optim_RMSprop_lr_1e-4\\nGoal:\\nDataset:\\nNotes:\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Data Science Group Project\")\n","\n","print(os.getcwd())\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsy9F0Y7Cgw_","executionInfo":{"status":"ok","timestamp":1770049911328,"user_tz":-330,"elapsed":1576,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}},"outputId":"835dab6d-3970-4a93-eb5a-de5fa6ad4447"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Data Science Group Project\n","['data', 'experiments', 'JustTests', 'OLD', 'MoveImagesFinal.ipynb', 'Splitting Dataset Into Train_Validation_Test_Sets.ipynb', 'RemovingBlackFinal.ipynb', 'Top-View Image Selection From MRI and CT Dataset.ipynb', 'old experiments']\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6eu6SOCyCOgI","executionInfo":{"status":"ok","timestamp":1770049998052,"user_tz":-330,"elapsed":6456,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"outputs":[],"source":["# =====================================================\n","# Imports\n","# =====================================================\n","\n","import platform\n","from pathlib import Path\n","import os\n","import cv2\n","import torch\n","import torch.multiprocessing as mp\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","import yaml\n","import json\n","import pandas as pd\n","import random\n","\n","# =====================================================\n","# Config & Reproducibility\n","# =====================================================\n","\n","def load_config(path):\n","    with open(path, \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","\n","# =====================================================\n","# Dataset\n","# =====================================================\n","\n","class DualImageDataset(Dataset):\n","    def __init__(self, path):\n","        # Load once\n","        self.raw_imgs, self.proc_imgs, self.labels = torch.load(path)\n","\n","        # Ensure proper dtype\n","        self.raw_imgs = self.raw_imgs.float()\n","        self.proc_imgs = self.proc_imgs.float()\n","        self.labels = self.labels.long()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.raw_imgs[idx], self.proc_imgs[idx], self.labels[idx]\n","\n","def dataset(transformed_data_dir, cfg):\n","    train_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"train_path\"])\n","    val_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"val_path\"])\n","    test_dataset = DualImageDataset(path=transformed_data_dir / cfg[\"data\"][\"test_path\"])\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","\n","# =====================================================\n","# Dataloaders\n","# =====================================================\n","\n","def dataloader(cfg, train_dataset, val_dataset, test_dataset):\n","    train_dataloader = DataLoader(train_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n","\n","    print(f\"Number of training samples: {len(train_dataset)}\")\n","    print(f\"Number of validation samples: {len(val_dataset)}\")\n","    print(f\"Number of testing samples: {len(test_dataset)}\")\n","\n","    print(f\"Length of TrainDataloader: {len(train_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of ValDataloader: {len(val_dataloader)} batches of {cfg['training']['batch_size']}\")\n","    print(f\"Length of TestDataloader: {len(test_dataloader)} batches of {cfg['training']['batch_size']}\")\n","\n","    return train_dataloader, val_dataloader, test_dataloader\n","\n","\n","# =====================================================\n","# Model\n","# =====================================================\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self, input_shape, hidden_units, output_shape, cfg):\n","        super().__init__()\n","\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","        # Compute flatten size dynamically\n","        with torch.no_grad():\n","            x = torch.zeros(1, input_shape, *tuple(cfg[\"data\"][\"image_size\"]))  # batch_size=1, input_shape channels\n","            x = self.conv_block_1(x)\n","            x = self.conv_block_2(x)\n","            n_features = x.numel() // x.shape[0]  # total features per sample\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=n_features, out_features=output_shape)\n","        )\n","\n","    def forward(self, raw_img, processed_img):\n","        x = torch.cat([raw_img, processed_img], dim=1)  # Concatenate raw + processed channels -> [B, 2, H, W]\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","def make_model(cfg, classes, device):\n","    model = CustomCNN(input_shape=cfg[\"model\"][\"input_dim\"], hidden_units=cfg[\"model\"][\"hidden_units\"],\n","                      output_shape=len(classes), cfg=cfg).to(device)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.RMSprop(model.parameters(), lr=cfg[\"training\"][\"lr\"])\n","\n","    return model, loss_func, optimizer\n","\n","\n","# =====================================================\n","# Training / Evaluation Utils\n","# =====================================================\n","\n","# =====================================================\n","# Train\n","# =====================================================\n","\n","def train_step(model, train_dataloader, loss_func, optimizer, device):\n","    train_loss, train_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.train()\n","\n","    for batch, (raw_X, processed_X, y) in enumerate(train_dataloader):\n","        raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","        train_y_pred = model(raw_X, processed_X)\n","\n","        loss = loss_func(train_y_pred, y)\n","        train_loss += loss.item()\n","\n","        # accuracy\n","        correct += (train_y_pred.argmax(dim=1) == y).sum().item()\n","        total += y.size(0)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    train_loss /= len(train_dataloader)\n","    train_acc = 100.0 * correct / total\n","\n","    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n\")\n","    return train_loss, train_acc\n","\n","\n","# =====================================================\n","# Validation\n","# =====================================================\n","\n","def val_step(model, val_dataloader, loss_func, device):\n","    val_loss, val_acc = 0, 0\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in val_dataloader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            val_y_pred = model(raw_X, processed_X)\n","\n","            val_loss += loss_func(val_y_pred, y).item()\n","\n","            # accuracy\n","            correct += (val_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        val_loss /= len(val_dataloader)\n","        val_acc = 100.0 * correct / total\n","\n","    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.2f}%\\n\")\n","    return val_loss, val_acc\n","\n","\n","def train_and_evaluate(model, epochs, train_dataloader, val_dataloader, loss_func, optimizer,\n","                       device):\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_func, optimizer, device)\n","        val_loss, val_acc = val_step(model, val_dataloader, loss_func, device)\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","    return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n","\n","\n","# =====================================================\n","# Test\n","# =====================================================\n","\n","def test_step(model, test_data_loader, loss_func, device):\n","    test_loss, test_acc = 0, 0\n","    correct = 0\n","    total = 0\n","    y_test_list = []\n","    y_pred_list = []\n","    y_pred_prob_list = []\n","\n","    model.eval()\n","    with torch.inference_mode():\n","        for raw_X, processed_X, y in test_data_loader:\n","            raw_X, processed_X, y = raw_X.to(device, non_blocking=True), processed_X.to(device, non_blocking=True), y.to(device)\n","\n","            test_y_pred = model(raw_X, processed_X)\n","            y_pred_prob_list.append(torch.softmax(test_y_pred, dim=1))\n","\n","            test_loss += loss_func(test_y_pred, y).item()\n","\n","            y_test_list.append(y.cpu())\n","            y_pred_list.append(test_y_pred.argmax(dim=1).cpu())\n","\n","            correct += (test_y_pred.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","        test_loss /= len(test_data_loader)\n","        test_acc = 100.0 * correct / total\n","\n","    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n","    return y_test_list, y_pred_list, y_pred_prob_list, test_acc"]},{"cell_type":"code","source":["experiment_path = Path(\"experiments/2026_02_02_exp_018_custom_cnn_optim_RMSprop_lr_1e-4\")\n","\n","config = load_config(experiment_path / \"config.yaml\")\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","# torch.use_deterministic_algorithms(True)\n","\n","random.seed(config[\"seed\"])\n","np.random.seed(config[\"seed\"])\n","torch.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed(config[\"seed\"])\n","torch.cuda.manual_seed_all(config[\"seed\"])\n","\n","device = \"cuda\" if config[\"device\"] == \"cuda\" and torch.cuda.is_available() else \"cpu\"\n","\n","train_dataset, val_dataset, test_dataset = dataset(Path(\"data/processed/mri\"), config)\n","\n","train_dataloader, val_dataloader, test_dataloader = dataloader(config, train_dataset, val_dataset, test_dataset)\n","\n","classes = ['glioma', 'meningioma', 'pituitary']\n","\n","model, loss_func, optimizer = make_model(config, classes, device)\n","\n","train_loss_list, train_acc_list, val_loss_list, val_acc_list = train_and_evaluate(model,\n","                                                                                    config[\"training\"][\"epochs\"],\n","                                                                                    train_dataloader, val_dataloader,\n","                                                                                    loss_func, optimizer, device)\n","\n","checkpoint = {\n","    \"epoch\": config[\"training\"][\"epochs\"],\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict(),\n","    \"config\": config,\n","    \"best_val_loss\": np.min(val_loss_list),\n","}\n","\n","torch.save(checkpoint, experiment_path / \"checkpoint.pth\")\n","\n","y_test_list, y_pred_list, y_pred_prob_list, test_accuracy = test_step(model, test_dataloader, loss_func, device)\n","\n","y_test_list = torch.cat(y_test_list).numpy()  # true labels\n","y_pred_list = torch.cat(y_pred_list).numpy()  # predicted class\n","y_pred_prob_list = torch.cat(y_pred_prob_list).cpu().numpy()  # predicted probabilities\n","\n","print(f\"Test: {y_test_list}\")\n","print(f\"Predicted: {y_pred_list}\")\n","print(f\"Predicted Probability: {y_pred_prob_list}\")\n","\n","# Convert metrics to JSON-friendly format\n","metrics = {\n","    \"train_loss\": [float(l) for l in train_loss_list],\n","    \"train_accuracy\": [float(a) for a in train_acc_list],\n","    \"val_loss\": [float(l) for l in val_loss_list],\n","    \"val_accuracy\": [float(a) for a in val_acc_list],\n","    \"test_accuracy\": test_accuracy,\n","    \"classes\": classes,\n","    \"epochs\": config[\"training\"][\"epochs\"],\n","    \"num_train_samples\": len(train_dataset),\n","    \"num_val_samples\": len(val_dataset),\n","    \"num_test_samples\": len(test_dataset),\n","    \"best_val_epoch\": int(np.argmin(val_loss_list)) + 1,\n","    \"best_val_loss\": float(np.min(val_loss_list)),\n","    \"best_val_accuracy\": float(val_acc_list[np.argmin(val_loss_list)])\n","}\n","\n","# Save metrics\n","metrics_path = experiment_path / \"metrics.json\"\n","with open(metrics_path, \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\"Metrics saved to {metrics_path}\")\n","\n","# Create DataFrame\n","metrics_df = pd.DataFrame({\n","    \"epoch\": list(range(config[\"training\"][\"epochs\"])),\n","    \"train_loss\": train_loss_list,\n","    \"train_accuracy\": [a for a in train_acc_list],\n","    \"val_loss\": val_loss_list,\n","    \"val_accuracy\": [a for a in val_acc_list]\n","})\n","\n","# Save to CSV\n","metrics_df.to_csv(experiment_path / \"train_val_metrics.csv\", index=False)\n","print(\"Train/Val metrics saved to train_val_metrics.csv\")\n","\n","# Convert predicted probabilities to a DataFrame\n","prob_df = pd.DataFrame(y_pred_prob_list, columns=[f\"prob_{cls}\" for cls in classes])\n","\n","# Create main DataFrame\n","test_df = pd.DataFrame({\"y_true\": y_test_list, \"y_pred\": y_pred_list})\n","\n","# Concatenate probabilities\n","test_df = pd.concat([test_df, prob_df], axis=1)\n","\n","# Save to CSV\n","test_df.to_csv(experiment_path / \"test_predictions.csv\", index=False)\n","print(\"Test predictions saved to test_predictions.csv\")\n","\n","env_info = {\n","    \"python_version\": platform.python_version(),\n","    \"pytorch_version\": torch.__version__,\n","    \"cuda_version\": torch.version.cuda,\n","    \"cudnn_version\": torch.backends.cudnn.version(),\n","    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    \"os\": platform.platform(),\n","}\n","\n","env_path = experiment_path / \"env_info.json\"\n","with open(env_path, \"w\") as f:\n","    json.dump(env_info, f, indent=4)\n","\n","print(f\"Environment Info saved to {env_path}\")"],"metadata":{"id":"1ZnX8JmMGB5y","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2e344e44b6634b76acb614899f219271","c9f23e45b7674e5b9222c562db97b565","e61f1994140f41e2b8dfb3f44d8cefa4","e30120392fd3472c8a816ccbabd3448f","63825fbcee5f40049661e3ddcc15bf7e","9fdba78512f34ca7831db2de108e1204","77f9880874fd439abb42664698b8c7e5","1ec4eab9e31147c597ad013042c35237","befd29eb338c4d46931d27f3790d45c5","22d80e5ebbc44e18afa9a8fa4eb3c812","edb64121660d4b47aa3ecfcc88e5953c"]},"outputId":"82bea4bf-8f07-4613-b499-554fe1e1fc7b","executionInfo":{"status":"ok","timestamp":1770050080468,"user_tz":-330,"elapsed":82400,"user":{"displayName":"Inzaman Sheshan","userId":"03733916943512366575"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples: 3181\n","Number of validation samples: 908\n","Number of testing samples: 456\n","Length of TrainDataloader: 100 batches of 32\n","Length of ValDataloader: 29 batches of 32\n","Length of TestDataloader: 15 batches of 32\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e344e44b6634b76acb614899f219271"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train loss: 0.64239 | Train acc: 69.07%\n","\n","Val loss: 0.57468 | Val acc: 73.02%\n","\n","Train loss: 0.46953 | Train acc: 78.65%\n","\n","Val loss: 0.57551 | Val acc: 71.15%\n","\n","Train loss: 0.40291 | Train acc: 82.77%\n","\n","Val loss: 0.37624 | Val acc: 85.02%\n","\n","Train loss: 0.35550 | Train acc: 84.88%\n","\n","Val loss: 0.35125 | Val acc: 86.01%\n","\n","Train loss: 0.32484 | Train acc: 86.51%\n","\n","Val loss: 0.33307 | Val acc: 87.00%\n","\n","Train loss: 0.28413 | Train acc: 88.59%\n","\n","Val loss: 0.33091 | Val acc: 87.44%\n","\n","Train loss: 0.27036 | Train acc: 88.97%\n","\n","Val loss: 0.35013 | Val acc: 86.34%\n","\n","Train loss: 0.25199 | Train acc: 90.32%\n","\n","Val loss: 0.35627 | Val acc: 84.25%\n","\n","Train loss: 0.23114 | Train acc: 91.76%\n","\n","Val loss: 0.27483 | Val acc: 91.63%\n","\n","Train loss: 0.22613 | Train acc: 91.73%\n","\n","Val loss: 0.26967 | Val acc: 90.42%\n","\n","Train loss: 0.19488 | Train acc: 92.80%\n","\n","Val loss: 0.31955 | Val acc: 87.11%\n","\n","Train loss: 0.19216 | Train acc: 92.64%\n","\n","Val loss: 0.25390 | Val acc: 92.29%\n","\n","Train loss: 0.18461 | Train acc: 93.15%\n","\n","Val loss: 0.24750 | Val acc: 93.28%\n","\n","Train loss: 0.16879 | Train acc: 93.93%\n","\n","Val loss: 0.22745 | Val acc: 93.72%\n","\n","Train loss: 0.15588 | Train acc: 94.28%\n","\n","Val loss: 0.24570 | Val acc: 93.06%\n","\n","Test loss: 0.21255 | Test acc: 92.32%\n","\n","Test: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1\n"," 0 0 1 1 1 1 1 1 1 1 1 1 0 1 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n"," 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0\n"," 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 0 2 1\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2]\n","Predicted Probability: [[7.6291978e-01 2.3705116e-01 2.9076376e-05]\n"," [8.5865372e-01 1.4119488e-01 1.5136747e-04]\n"," [8.5296369e-01 1.4703523e-01 1.0534915e-06]\n"," ...\n"," [8.4443629e-05 8.1870327e-05 9.9983370e-01]\n"," [1.8318203e-12 4.3459142e-08 1.0000000e+00]\n"," [1.8780375e-11 8.4987596e-06 9.9999154e-01]]\n","Metrics saved to experiments/2026_02_02_exp_018_custom_cnn_optim_RMSprop_lr_1e-4/metrics.json\n","Train/Val metrics saved to train_val_metrics.csv\n","Test predictions saved to test_predictions.csv\n","Environment Info saved to experiments/2026_02_02_exp_018_custom_cnn_optim_RMSprop_lr_1e-4/env_info.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"C2FhPMjqfIVt"},"execution_count":null,"outputs":[]}]}